{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:\\\\Jave\\\\Seasonality\\\\dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>02/12/2017</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>09/12/2017</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15/12/2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19/12/2017</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>21/12/2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  quantity\n",
       "0  02/12/2017       2.0\n",
       "1  09/12/2017       2.0\n",
       "2  15/12/2017       1.0\n",
       "3  19/12/2017       2.0\n",
       "4  21/12/2017       1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x256fc0c46c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot(x = 'date', y = 'quantity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale control variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numericas = ['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in features_numericas:\n",
    "    mean, std = data[item].mean(), data[item].std()\n",
    "    scaled_features[item] = [mean, std]\n",
    "    data.loc[:, item] = (data[item] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  quantity\n",
      "0   02/12/2017  0.102783\n",
      "1   09/12/2017  0.102783\n",
      "2   15/12/2017 -0.465548\n",
      "3   19/12/2017  0.102783\n",
      "4   21/12/2017 -0.465548\n",
      "..         ...       ...\n",
      "89  26/04/2019 -0.465548\n",
      "90  29/04/2019 -0.465548\n",
      "91  30/04/2019  0.671114\n",
      "92  02/05/2019  1.239445\n",
      "93  04/05/2019 -0.465548\n",
      "\n",
      "[94 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo os dados em treino, teste e validação\n",
    "\n",
    "Salvaremos os últimos 21 dias dos dados para serem usados como um conjunto de testes depois de treinarmos a rede. Usaremos este conjunto para fazer previsões e compará-los com o número real de ciclistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os últimos 21 dias\n",
    "test_data = data[:20]\n",
    "data = data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date\n",
      "0   02/12/2017\n",
      "1   09/12/2017\n",
      "2   15/12/2017\n",
      "3   19/12/2017\n",
      "4   21/12/2017\n",
      "5   23/12/2017\n",
      "6   06/01/2018\n",
      "7   08/01/2018\n",
      "8   12/01/2018\n",
      "9   16/01/2018\n",
      "10  23/01/2018\n",
      "11  24/01/2018\n",
      "12  26/01/2018\n",
      "13  27/01/2018\n",
      "14  03/02/2018\n",
      "15  10/02/2018\n",
      "16  14/02/2018\n",
      "17  17/02/2018\n",
      "18  05/04/2018\n",
      "19  09/04/2018\n",
      "    quantity\n",
      "0   0.102783\n",
      "1   0.102783\n",
      "2  -0.465548\n",
      "3   0.102783\n",
      "4  -0.465548\n",
      "5  -0.465548\n",
      "6  -0.465548\n",
      "7  -0.465548\n",
      "8  -0.465548\n",
      "9  -0.465548\n",
      "10 -0.465548\n",
      "11 -0.465548\n",
      "12  0.102783\n",
      "13 -0.465548\n",
      "14  0.671114\n",
      "15 -0.465548\n",
      "16 -0.465548\n",
      "17 -0.465548\n",
      "18 -0.465548\n",
      "19 -0.465548\n"
     ]
    }
   ],
   "source": [
    "# Separando os dados em variáveis preditoras e variável target\n",
    "target_fields = ['quantity']\n",
    "features, targets = data.drop(target_fields, axis = 1), data[target_fields]\n",
    "test_features, test_targets = test_data.drop(target_fields, axis = 1), test_data[target_fields]\n",
    "\n",
    "print(features)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dividir os dados em dois conjuntos, um para treinamento e outro para validação à medida que a rede está sendo treinada. Como se trata de dados de séries temporais, treinamos em dados históricos, então tentaremos prever os dados futuros (o conjunto de validação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_targets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-34a3a3820fdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mval_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(train_features)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_targets' is not defined"
     ]
    }
   ],
   "source": [
    "# Mantenha os últimos 60 dias dos dados restantes como um conjunto de validação\n",
    "#train_features, train_targets = features[:60], targets[:60]\n",
    "val_features, val_targets = features[60:], targets[60:]\n",
    "#print(train_features)\n",
    "print(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-21\n",
      "2017-11-21\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "today = date.today()\n",
    "begin = date.today()- timedelta(days=730)\n",
    "print(today)\n",
    "print(begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo a Rede Neural\n",
    "\n",
    "Abaixo iremos construir a rede. Vamos configurar o Feed Forward e os hiperparâmetros: a taxa de aprendizado, o número de unidades ocultas e o número de passadas de treinamentos (epochs).\n",
    "\n",
    "A rede possui duas camadas, uma camada oculta e uma camada de saída. A camada oculta usará a função sigmoid para ativações. A camada de saída tem apenas um nó e é usada para a regressão, a saída do nó é igual à entrada do nó. Ou seja, a função de ativação é $ f (x) = x $. Uma função que recebe o sinal de entrada e gera um sinal de saída, mas leva em consideração o limite (threshold), é chamada de função de ativação. Trabalhamos através de cada camada da nossa rede, calculando as saídas para cada neurônio. Todas as saídas de uma camada tornam-se entradas para os neurônios na próxima camada. Esse processo é chamado de * propagação direta * (Feed Forward).\n",
    "\n",
    "Usamos os pesos para propagar os sinais para a frente, da entrada para as camadas de saída em uma rede neural. Usamos os pesos para propagar também o erro de trás da saída para a rede para atualizar nossos pesos. Isso é chamado * backpropagation *.\n",
    "\n",
    "> ** Dica: ** Você precisará da derivada da função de ativação de saída ($ f (x) = x $) para a implementação de backpropagation. Se você não está familiarizado com o cálculo, esta função é equivalente à equação $ y = x $. Qual é a inclinação dessa equação? Essa é a derivada de $ f (x) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe da Rede Neural\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate, verbose = False):\n",
    "        \n",
    "        # Defina o número de nós nas camadas de entrada, oculta e de saída.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Inicializando os pesos\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.hidden_nodes**-0.5, \n",
    "                                       (self.hidden_nodes, self.input_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                       (self.output_nodes, self.hidden_nodes))\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        self.verbose = verbose \n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Rede Neural iniciada com:\\ninput_nodes: {}\\nhidden_nodes: {}\\noutput_nodes: {}\\nlearning_rate: {}\\n\".format(\n",
    "                self.input_nodes, self.hidden_nodes, self.output_nodes, self.lr\n",
    "            ))\n",
    "        \n",
    "        self.hidden_layer_activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "        self.hidden_layer_derivate_activation_function = lambda sigmoid: sigmoid * (1 - sigmoid)\n",
    "        self.output_layer_activation_function = lambda x: x \n",
    "        self.output_layer_derivate_activation_function = lambda x: 1 \n",
    "        \n",
    "        # Ativação\n",
    "        self.activation_function = self.hidden_layer_activation_function \n",
    "    \n",
    "    def forward_pass(self, inputs):\n",
    "        \n",
    "        # Forward pass #\n",
    "        \n",
    "        # Sinais da camada de entrada\n",
    "        hidden_inputs = np.dot(self.weights_input_to_hidden, inputs) \n",
    "        \n",
    "        # Sinais da camada oculta\n",
    "        hidden_outputs = self.hidden_layer_activation_function(hidden_inputs) \n",
    "        \n",
    "        # Sinais na camada de saída final\n",
    "        final_inputs = np.dot(self.weights_hidden_to_output, hidden_outputs) \n",
    "        final_outputs = self.output_layer_activation_function(final_inputs)\n",
    "        return [hidden_inputs, hidden_outputs, final_inputs, final_outputs]\n",
    "    \n",
    "    def backward_pass(self, inputs, targets, hidden_inputs, hidden_outputs, final_inputs, final_outputs):\n",
    "        \n",
    "        # Backward pass #\n",
    "        output_errors = targets - final_outputs\n",
    "        output_grad = self.output_layer_derivate_activation_function(final_outputs)\n",
    "        \n",
    "        # Backpropagated error\n",
    "        \n",
    "        # Erros propagados para a camada oculta\n",
    "        hidden_errors = output_errors * output_grad * self.weights_hidden_to_output \n",
    "        hidden_grad = self.hidden_layer_derivate_activation_function(hidden_outputs)\n",
    "            \n",
    "        return [output_errors, hidden_errors, hidden_grad, output_grad]\n",
    "\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        \n",
    "        # Converta a lista de entradas para a matriz 2d\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs, hidden_outputs, final_inputs, final_outputs = self.forward_pass(inputs)\n",
    "        output_errors, hidden_errors, hidden_grad, output_grad = self.backward_pass(inputs, targets, hidden_inputs, hidden_outputs, final_inputs, final_outputs)\n",
    "\n",
    "        # Atualização de pesos para saída com passo de descida de gradiente\n",
    "        self.weights_hidden_to_output += self.lr * np.dot(output_errors * output_grad, hidden_outputs.T) \n",
    "        self.weights_input_to_hidden += self.lr * np.dot(hidden_errors.T * hidden_grad, inputs.T)\n",
    " \n",
    "    def run(self, inputs_list):\n",
    "        # Executa um passo para a frente pela rede\n",
    "        inputs = np.array(inputs_list, ndmin = 2).T\n",
    "        \n",
    "        _, _, _, final_outputs = self.forward_pass(inputs)\n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, Y):\n",
    "    return np.mean((y-Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando a Rede\n",
    "\n",
    "Aqui você configurará os hiperparâmetros da rede. A estratégia é encontrar hiperparâmetros, de modo que o erro no conjunto de treinamento seja baixo, mas você não tenha overfitting. Se você treinar a rede por muito tempo ou tiver muitos nós ocultos, pode tornar-se excessivamente específico para o conjunto de treinamento e não conseguirá generalizar para o conjunto de validação. Ou seja, a perda no conjunto de validação começará a aumentar à medida que a queda do conjunto de treinamento cai.\n",
    "\n",
    "Você também usará um método conhecido como Descida de Gradiente Estocástica (SGD) para treinar a rede. A idéia é que, para cada passagem de treinamento, você pega uma amostra aleatória dos dados em vez de usar todo o conjunto de dados. Você usa muito mais passagens de treinamento do que com descida de gradiente normal, mas cada passagem é muito mais rápida. Isso acaba treinando a rede de forma mais eficiente. Você aprenderá mais sobre o SGD mais tarde.\n",
    "\n",
    "### Escolhendo número de epochs\n",
    "Este é o número de vezes que o conjunto de dados passará pela rede, cada vez que atualizar os pesos. À medida que o número de épocas aumenta, a rede se torna melhor e melhor em prever os alvos no conjunto de treinamento. Você precisará escolher épocas suficientes para treinar a rede bem, mas não demais, ou você terá overfitting.\n",
    "\n",
    "### Escolhendo a taxa de aprendizagem\n",
    "Isso reduz o tamanho das atualizações de peso. Se essa taxa for muito grande, os pesos tendem a explodir e a rede não consegue se ajustar aos dados. Uma boa escolha para começar é 0.1. Se a rede tiver problemas ao ajustar os dados, tente reduzir a taxa de aprendizado. Note-se que quanto menor for a taxa de aprendizagem, menores as etapas nas atualizações de peso e quanto maior, demora a convergir a rede neural.\n",
    "\n",
    "### Escolhendo o número de nodes ocultos\n",
    "Os nós mais ocultos que você tem, as previsões mais precisas que o modelo fará. Experimente alguns números diferentes e veja como isso afeta o desempenho. Você pode observar o dicionário de perdas para uma métrica da performance da rede. Se o número de unidades escondidas for muito baixo, então o modelo não terá espaço suficiente para aprender e, se for muito alto, há muitas opções para a direção que a aprendizagem pode levar. O truque aqui é encontrar o equilíbrio certo no número de unidades escondidas que você escolher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Configurando os hiperparametros\n",
    "epochs = 3000\n",
    "learning_rate = 0.1\n",
    "hidden_nodes = 27\n",
    "output_nodes = 1\n",
    "\n",
    "N_i = train_features.shape[1]\n",
    "network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate, True)\n",
    "\n",
    "losses = {'train':[], 'validation':[]}\n",
    "\n",
    "for e in range(epochs):\n",
    "    # Percorrer um lote aleatório de 128 registros do conjunto de dados de treinamento\n",
    "    batch = np.random.choice(train_features.index, size=128)\n",
    "    for record, target in zip(train_features.iloc[batch].values, \n",
    "                              train_targets.iloc[batch]['quantity']):\n",
    "        network.train(record, target)\n",
    "    \n",
    "    # Imprimir o progresso do treinamento\n",
    "    train_loss = MSE(network.run(train_features), train_targets['quantity'].values)\n",
    "    \n",
    "    val_loss = MSE(network.run(val_features), val_targets['quantity'].values)\n",
    "    \n",
    "    sys.stdout.write(\"\\rProgresso: \" + str(100 * e/float(epochs))[:4] \\\n",
    "                     + \"% ... Erro no Treinamento: \" + str(train_loss)[:5] \\\n",
    "                     + \" ... Erro na Validação: \" + str(val_loss)[:5])\n",
    "    \n",
    "    losses['train'].append(train_loss)\n",
    "    losses['validation'].append(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O número de epochs como 3000 é uma boa escolha em si, mas a combinação de hiperparâmetros deve ser ajustada adequadamente. Tente sintonizar todos os hiperparâmetros em paralelo. As perdas de treinamento e validação são aceitáveis. Ao observar o gráfico de perda de treinamento-validação, você não acha que há muito ruído nos dados? Isso pode ser melhorado ajustando corretamente os hiperparâmetros. Tente testar com várias combinações e observe a resposta do modelo. O número de iterações deve ser escolhido para que a perda de treinamento seja baixa e a perda de validação não aumente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Às vezes, a rede não converge quando a taxa de aprendizado é de 0.1. As etapas de atualização de peso são muito grandes com essa taxa de aprendizado e os pesos acabam por não convergir. Devido à alta taxa de aprendizado, o modelo ignora os pontos mínimos. Ao diminuir a taxa de aprendizagem, você pode obter menor perda de validação e o ruído no gráfico também diminuirá. Tente observar a resposta do modelo para valores como 0.08, 0.05, 0.01, 0.008, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses['train'], label = 'Erro no Treinamento')\n",
    "plt.plot(losses['validation'], label = 'Erro na Validação')\n",
    "plt.legend()\n",
    "plt.ylim(ymax = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo as Previsões\n",
    "\n",
    "Aqui, usamos os dados do teste para ver como a rede está modelando os dados. Se algo estiver completamente errado, certifique-se de que cada etapa da sua rede esteja implementada corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,4))\n",
    "\n",
    "mean, std = scaled_features['cnt']\n",
    "predictions = network.run(test_features)*std + mean\n",
    "ax.plot(predictions[0], label = 'Previsões')\n",
    "ax.plot((test_targets['cnt']*std + mean).values, label='Data')\n",
    "ax.set_xlim(right = len(predictions))\n",
    "ax.legend()\n",
    "\n",
    "dates = pd.to_datetime(df.iloc[test_data.index]['dteday'])\n",
    "dates = dates.apply(lambda d: d.strftime('%b %d'))\n",
    "ax.set_xticks(np.arange(len(dates))[12::24])\n",
    "_ = ax.set_xticklabels(dates[12::24], rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando os Resultados\n",
    " \n",
    "Responda estas perguntas sobre seus resultados. Quão bem o modelo prediz os dados? Onde ele falha? Por que ele falha?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O modelo parece ter resultados bastante decentes, mas a precisão da previsão parece diminuir à medida que avançamos no tempo (a partir de 21 de dezembro). Este fenômeno provavelmente deve-se à existência de variáveis que poderiam ter acontecido entre 21 de dezembro e 31 de dezembro (parece suspeito, pois é o período das celebrações, muitos eventos inesperados podem acontecer durante esse lapso de tempo, o que poderia levar as pessoas a alugar mais bicicletas do que durante um período normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
